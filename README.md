# API Data Ingest Pipeline

A small Python project demonstrating a simple data ingestion pipeline:

- Fetch data from a public REST API  
- Store structured results in a SQL database  
- Query the stored data for analysis  
- Use clean, modular Python scripts for  backend workflows  

This project was done for fun while I had some spare time. 

---

## Project Overview

This pipeline retrieves Pok√©mon data from the public **Pok√©API**, stores it in a local SQLite database, and runs SQL queries to analyze the data.

### Key Skills Demonstrated
- Python scripting  
- Consuming REST APIs  
- SQL database creation and data insertion  
- Querying and filtering data  
- Basic ETL (Extract ‚Üí Transform ‚Üí Load) concepts  
- Modular code organization  
- Lightweight backend data pipeline patterns  

---

## üìÇ Project Structure

api_data_ingest_pipeline/
‚îú‚îÄ‚îÄ fetch_data.py # Fetches data from the API and inserts into SQL
‚îú‚îÄ‚îÄ db_setup.py # Creates the SQLite database and table
‚îú‚îÄ‚îÄ query_data.py # Queries the stored API data
‚îî‚îÄ‚îÄ README.md # Project documentation



---

## How to Run the Project

### Install Python 

Ensure Python is installed:

python --version

---

### Create the database

python db_setup.py


This generates a `api_data.db` SQLite database with a table for Pok√©mon data.

---

### Fetch API data and load it into SQL

python fetch_data.py


This script calls the Pok√©API for Pok√©mon IDs 1‚Äì5 and inserts:

- `id`  
- `name`  
- `base_experience`  

into the SQL table.

---

### Query the data

python query_data.py


This prints all Pok√©mon with **base_experience > 100**, demonstrating a simple SQL filter query.

---

## Example Output

**Fetching & inserting:**

API data fetched and stored.


**Query results:**

High Experience Pok√©mon:
('charizard', 240)
('blastoise', 239)


---

## Database Schema

The SQLite table created:

```sql
CREATE TABLE IF NOT EXISTS pokemon (
    id INTEGER PRIMARY KEY,
    name TEXT NOT NULL,
    base_experience INTEGER
);


